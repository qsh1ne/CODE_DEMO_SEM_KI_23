{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62bc6e71",
   "metadata": {},
   "source": [
    "# Code Demo Process Mining\n",
    "Quirin Joshua Groszeibl  \n",
    "Aktuelle Themen der KI Seminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef56b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22481152",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Zuerst brauchen wir Daten, die wir verwerten können. In diesem Fall laden wir dazu eine CSV Datei hoch. Das Beispiel hierbei ist ein Datensatz von Keggle mit über 27k Reihen Eventlogs einer Autoversicherungsfirma, diese begrenzen wir für diese Demo auf 200 Reihen, damit das Complilieren nicht allzulange dauert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a6bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the event log as a DataFrame\n",
    "event_log = pd.read_csv('/home/qsh1ne/PM_Code_Demo/Insurance_claims_event_log.csv',\n",
    "                        nrows=200, usecols=['case_id', 'activity_name', 'timestamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d3119c8",
   "metadata": {},
   "source": [
    "## Daten verstehen\n",
    "\n",
    "Damit wir eine Fehlerfreie Analyse durchführen können, benötigen wir zuerst ein Verständnis für unsere Daten. Eine Frequenzanalyse hilft uns direkte Zusammenhänge zwischen den Variabeln besser zu verstehen. Für die spätere Visualisierung erstellen wir anschließend einen gerichteten Graph, dessen Knoten wir mit den Subprozessen der Case ID bestücken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c05bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform frequency analysis to get the directly-follows relations\n",
    "dfg = event_log.groupby(['case_id', event_log['activity_name'].shift(-1)]).size().reset_index(name='count')\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for _, row in dfg.iterrows():\n",
    "    graph.add_edge(row['activity_name'], row['activity_name'], weight=row['count'])\n",
    "\n",
    "# Visualize the graph\n",
    "pos = nx.spring_layout(graph, seed=42)\n",
    "labels = nx.get_edge_attributes(graph, 'weight')\n",
    "weights = [graph[u][v]['weight'] / 10 for u, v in graph.edges()]\n",
    "nx.draw_networkx(graph, pos, with_labels=True, node_size=500, node_color='lightblue',\n",
    "                 edge_color='gray', width=weights, font_size=8)\n",
    "nx.draw_networkx_edge_labels(graph, pos, edge_labels=labels, font_size=6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "650b4a0d",
   "metadata": {},
   "source": [
    "Anschließend lassen wir und den Graphen als Bild ausgeben, um notfalls später auf die Ergebnisse zurückzukommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9aa5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the process graph as an image file\n",
    "output_dir = '/home/qsh1ne/PM_Code_Demo/output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "process_graph_file = os.path.join(output_dir, 'process_graph.png')\n",
    "plt.savefig(process_graph_file)\n",
    "\n",
    "print(f\"Process graph saved as {process_graph_file}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbcdf78a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Beispiel**: Die EventLogs der Versicherungsfirma beziehen sich auf Cases, welche jeweils in 6 Schritten aufgespalten werden, wie auf der Abbildung unten zu sehen. Anhand der gleichmäßigen Größe aller Subprozesse, lässt sich darauf schließen, dass diese alle in etwa gleich oft vorkommen.\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/Ep2op8c4Gd9Fx6q?x=1920&y=579&a=true&file=process_graph.png&scalingup=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d6bd827",
   "metadata": {},
   "source": [
    "## Process Spektrum errechnen\n",
    "\n",
    "Das Errechnen des Process Spektrums ganz einfach über das Zählen der einzelnen Aktivitäten in der Anzahl. Jeder Subprocess muss einen sehr ähnlichen Ablauf haben, um mit dem PSM gute Vorhersagen treffen zu können. Beispielsweise eignen sich Maschinendaten oder Bürokratische Abläufe sehr gut, während Daten von Sportwettkämpfen hierbei weniger gute Ergebnisse liefern.\n",
    "\n",
    "Es gilt: **Je ähnlicher die Processe, desto einfach die Auswertung.** \n",
    "\n",
    "Auch hier visualisieren wir die Ergebnisse zuerst und speichern diese anschließend als Bild ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c138aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate process spectrum\n",
    "spectrum = event_log['activity_name'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Plot the process spectrum\n",
    "plt.figure()\n",
    "spectrum.plot(kind='bar', color='lightblue')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Process Spectrum')\n",
    "\n",
    "# Save the process spectrum plot as an image file\n",
    "spectrum_plot_file = os.path.join(output_dir, 'process_spectrum.png')\n",
    "plt.savefig(spectrum_plot_file)\n",
    "\n",
    "print(f\"Process spectrum saved as {spectrum_plot_file}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a56504e1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Beispiel:** Hierbei fällt auch schon der erste Fehler auf, die ersten 200 Reihen anstelle der gesamten 27k Reihen, verfäscht in diesen Fall aus 2 Gründen die Ergebnisse. Zum einen ist 200%6 =! 0, dementsprechend fehlen Subprocesse des letzten eigentlichen Processes, aber auch betracheten wir weniger als 0,007% der Datenmenge. So können unmöglich auschlagkräftige Ergebnisse erzielt werden, aber für den Zweck dieser kleinen Demonstration ist es genügend.\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/GDCeE2JQW6m2rZz?x=1920&y=579&a=true&file=process_spectrum.png&scalingup=0) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37f7260b",
   "metadata": {},
   "source": [
    "## Performance Spektrum errechnen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70f45f43",
   "metadata": {},
   "source": [
    "Die ersten komplexeren Berechnungen nimmt uns hierbei die Pandas Libary ab, in dem diese die Eventlogs in zuerst in eine einheitliches und auswertbares Zeitformat umformt. Wir setzen die Startzeiten auf die geringste Dauer, und die Endzeiten auf die höschste der jeweiligen Cases. Anschließend subtrahieren wir Startzeit von der Endzeit, und uns bleibt eine durschnittliche Zeit für die Dauer der jeweiligen Aktivitäten.\n",
    "\n",
    "Anschließend visualisieren wir unsere Ergebnisse wieder, und geben diese als Bild aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate case durations\n",
    "event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
    "start_times = event_log.groupby('case_id')['timestamp'].min()\n",
    "end_times = event_log.groupby('case_id')['timestamp'].max()\n",
    "case_durations = end_times - start_times\n",
    "\n",
    "# Plot the performance spectrum\n",
    "plt.figure()\n",
    "case_durations.dt.total_seconds().plot(kind='bar', color='lightblue')\n",
    "plt.xlabel('Case ID')\n",
    "plt.ylabel('Duration (seconds)')\n",
    "plt.title('Performance Spectrum')\n",
    "\n",
    "# Save the performance spectrum plot as an image file\n",
    "performance_spectrum_file = os.path.join(output_dir, 'performance_spectrum.png')\n",
    "plt.savefig(performance_spectrum_file)\n",
    "\n",
    "print(f\"Performance spectrum saved as {performance_spectrum_file}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa93d6d7",
   "metadata": {},
   "source": [
    "Auch hierbei ist die Verfälschung deutlich zu erkennen, die einzelnen Subprocesse der Processe wurden unter der gemeinsamen Case ID zusammengefasst. Da die Dauer dieser Processe stark variiert, und der kürzste Teil des Processe nur wenige Sekunden dauert, ist auch mit dem Ergebnisse wenig anzufangen.\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/MgAa2KbbPTRTwsE?x=1920&y=579&a=true&file=performance_spectrum.png&scalingup=0)\n",
    "\n",
    "\n",
    "\n",
    "Neben den hier verwendeten Libarys sind folgende libarys erwähnenswert, allerdings dauert die Implimentation wesentlich länger und diese Demo ist zeitlich sehr beschränkt.\n",
    "\n",
    " - pm4py\n",
    " - pmi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8550aac",
   "metadata": {},
   "source": [
    "## Prom 6.9\n",
    "\n",
    "Die Prom Plattform ist ein plugin-basierendes Framework speziell für Process Mining. Zentriert auf drei Basiskonzepten. \n",
    "\n",
    "Data Objects (1) im Workspace Tab (2)\n",
    "Plugins (3)\n",
    "Visualisierung (4)\n",
    "\n",
    "![alt text](https://promtools.org/wp-content/uploads/2022/12/prom_tabs-1024x346.png)\n",
    "\n",
    "## Workspace\n",
    "\n",
    "Ansicht (5) von allen Objekten, den Favorisierten Objekten und Importierten Objekten.\n",
    "\n",
    "Objekte importierbar über den import button (6) oder via drag&drop.\n",
    "\n",
    "Im workspace kann außerdem:\n",
    "(7) favorisiert (Stern), angeschaut (Auge), Plugin gestartet (Play) oder gelöscht (Kreuz),\n",
    "(8) umbenannt,\n",
    "(9) exportiert werden.\n",
    "\n",
    "![alt text](https://promtools.org/wp-content/uploads/2022/12/prom_workspace-1024x576.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b329ceff",
   "metadata": {},
   "source": [
    "## Praktische Anwendung\n",
    "Die Code Demo ist ein wenig kurz an tatsächlichen Code gekommen, aber mir war es wichtiger einen sinnvollen Einblick in die praktische Arbeit mit Process Mining zu geben.\n",
    "\n",
    "Fangen wir nun mit der Umwandlung der CSV-Datei an. Zualler erst schauen wir uns dazu wie vorab beschrieben den Inhalt an für ein Verständnis der Daten, und klassifizieren die Eingabevariabeln.\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/qCd95sMpQoNxCe4?x=952&y=561&a=true&file=CSV_Klassifizieren.png&scalingup=0)\n",
    "\n",
    "## Umwandlung in .XES Format\n",
    "\n",
    "Anschließend übertrage wir die Variabelklassifizierung und alle Spalten und Reihen der CSV-Datei in ein XES Format, dies machen wir mit dem zugehörigen Standard-Plugin von ProM 6.9.\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/X8f8M2TLHABX8zg?x=1920&y=579&a=true&file=CSV_Convert.png&scalingup=0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse \n",
    "\n",
    "Die XES-Datei können wir problemlos in das Performance Spektrum Plugin einfüttern. \n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/WTBF39MAef4GaGN?x=1920&y=579&a=true&file=PSM_PM_START.png&scalingup=0)\n",
    "\n",
    "Das Feintuning der Parameter und das setzen eines eigenen Classifier ist optimal, kann aber je nach dem Ziel des Anwenders stark die Ergebnisse berichtigen und verfälschen. Die ersten zwei Ausgabebilder werten die Versicherungsdaten in Quantilen aus:\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/dH9959osKBkyGXk?x=1920&y=579&a=true&file=PSM_Quartile_1.png&scalingup=0)\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/PLenw6S3zF3CxtE?x=1920&y=579&a=true&file=PSM_UANTILE_2.png&scalingup=0)\n",
    "\n",
    "hier die mediale Auswertung:\n",
    "\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/bg9y3t9gdikANSq?x=1920&y=579&a=true&file=PSM_Medianbased1.png&scalingup=0)\n",
    "![alt text](https://nextcloud.th-deg.de/apps/files_sharing/publicpreview/cLfPWsQ4mLgGyYK?x=1920&y=579&a=true&file=PSM_MEDIAN_3.png&scalingup=0)\n",
    "\n",
    "## Auswertung\n",
    "\n",
    "Zur Auswertung nehme ich den medialen Ansatz her, da er hierbei mehr Sinn ergibt. Man kann relativ deutlich erknnen bei der 2. Abbildung, dass die ersten Prozesse die erste Benachrichtigung über den Verlust ist, und die letzte das Abschließen durch abgeschlossene Bezahlung oder durch Entscheidung keine Zahlung zu senden ist. Ebenfalls zu sehen ist, dass die meisten sehr (Dunkelblau) und langsamen (Orange) sich innerhalb sehr speziellen Prozessen befinden, während die häufigsten Prozesse (First Notification) schon sehr gut optimiert sind und komplett normal im Durschnitt ablaufen.\n",
    "In der ersten Abildung ist ebenfalls zu sehen, wie verschiedene Prozesse sich überschneiden. Die Linien stellen jeweils einen Prozess von Beginn bis Ende da. Dies ist bei den oft vorkommenden Prozessen leider sehr unübersichtlich, während es bei den weniger Häufigen Prozessen zu wesentlich besser sichtbaren Resultaten führt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniforge3-4.10.1-5]",
   "language": "python",
   "name": "conda-env-miniforge3-4.10.1-5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
